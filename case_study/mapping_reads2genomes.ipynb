{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping simulated reads to reference genomes\n",
    "\n",
    "Samuel Barnett\n",
    "\n",
    "### Introduction\n",
    "\n",
    "Here I'll map reads from metagenomic-SIP and shotgun metagenomic simulations to the reference genomes that were used to generate them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Initialization\n",
    "\n",
    "First I need to import the python modules I'll use, set some variables, initiate R magic, and create/get into the working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "mainDir = '/home/sam/data/SIPSim2_data/RealWorld_study3/'\n",
    "mappingDir = os.path.join(mainDir, 'read_mapping')\n",
    "genomeDir = '/home/sam/databases/ncbi_genomes/ncbi-genomes-2019-01-25/'\n",
    "nprocs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sam/data/SIPSim2_data/RealWorld_study3/read_mapping\n",
      "/home/sam/databases/ncbi_genomes/ncbi-genomes-2019-01-25/\n"
     ]
    }
   ],
   "source": [
    "# making directories\n",
    "## working directory\n",
    "if not os.path.isdir(mappingDir):\n",
    "    os.makedirs(mappingDir)\n",
    "%cd $mappingDir\n",
    "\n",
    "## genome directory\n",
    "if not os.path.isdir(genomeDir):\n",
    "    print(\"Genome directory does not exist!!!\")\n",
    "else:\n",
    "    print(genomeDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Generating master genome multifasta files\n",
    "\n",
    "For this to work I need all reference genomes from each set in a single multi-fasta file. I'll then map reads to this master file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatinating 500 genomes for low_GC_skew into /home/sam/data/SIPSim2_data/RealWorld_study3/read_mapping/lowGC_genomes.fasta\n",
      "Concatinating 500 genomes for medium_GC into /home/sam/data/SIPSim2_data/RealWorld_study3/read_mapping/medGC_genomes.fasta\n",
      "Concatinating 500 genomes for high_GC_skew into /home/sam/data/SIPSim2_data/RealWorld_study3/read_mapping/highGC_genomes.fasta\n"
     ]
    }
   ],
   "source": [
    "genset_dict = {'low_GC_skew': 'lowGC', \n",
    "               'medium_GC': 'medGC', \n",
    "               'high_GC_skew': 'highGC'}\n",
    "depth_dict = {'depth5MM': '5MM', \n",
    "              'depth10MM': '10MM'}\n",
    "exp_dict = {'SIP': 'window', 'nonSIP': 'nonSIP'}\n",
    "\n",
    "cmd_dict = {}\n",
    "\n",
    "for genome_set in ['low_GC_skew', 'medium_GC', 'high_GC_skew']:\n",
    "    index_file = '_'.join([genome_set, 'genome_index.txt'])\n",
    "    index_file = os.path.join(mainDir, index_file)\n",
    "    ref_list = ' '.join([os.path.join(genomeDir, x) for x in pd.read_table(index_file, names = ['genome', 'file'])['file']])\n",
    "    cat_fasta = '_'.join([genset_dict[genome_set], 'genomes.fasta'])\n",
    "    cat_fasta = os.path.join(mappingDir, cat_fasta)\n",
    "    cmd = ' '.join(['cat', ref_list, '>', cat_fasta])\n",
    "    print(' '.join(['Concatinating', \n",
    "                    str(len(pd.read_table(index_file, names = ['genome', 'file'])['file'])), \n",
    "                    'genomes for', genome_set, 'into', cat_fasta]))\n",
    "    os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Mapping reads with bbmap\n",
    "\n",
    "I want to return coverage stats for each reference genome into each read library generated from that set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sam/data/SIPSim2_data/RealWorld_study3/read_mapping/lowGC_5MM_SIP\n",
      "Mapping reads for low_GC_skew SIP experiment depth5MM read depth library 1\n",
      "Reordering reads\n",
      "Mapping reads\n"
     ]
    }
   ],
   "source": [
    "genset_dict = {'low_GC_skew': 'lowGC', \n",
    "               'medium_GC': 'medGC', \n",
    "               'high_GC_skew': 'highGC'}\n",
    "depth_dict = {'depth5MM': '5MM', \n",
    "              'depth10MM': '10MM'}\n",
    "exp_dict = {'SIP': 'window', 'nonSIP': 'nonSIP'}\n",
    "    \n",
    "for genome_set in ['low_GC_skew', 'medium_GC', 'high_GC_skew']:\n",
    "    \n",
    "    cat_fasta = '_'.join([genset_dict[genome_set], 'genomes.fasta'])\n",
    "    cat_fasta = os.path.join(mappingDir, cat_fasta)\n",
    "    \n",
    "    for depth in ['depth5MM', 'depth10MM']:\n",
    "        fastqDir = os.path.join(mainDir, genome_set, depth)\n",
    "\n",
    "        for exp_type in ['SIP', 'nonSIP']:\n",
    "            submappingDir = '_'.join([genset_dict[genome_set], depth_dict[depth], exp_type])\n",
    "            submappingDir = os.path.join(mappingDir, submappingDir)\n",
    "            if not os.path.exists(submappingDir):\n",
    "                os.makedirs(submappingDir)\n",
    "            %cd $submappingDir\n",
    "\n",
    "            for lib in [1, 2, 3, 4, 5, 6]:\n",
    "                print(' '.join(['Mapping reads for', genome_set, \n",
    "                                exp_type, 'experiment', \n",
    "                                depth, 'read depth library', str(lib)]))\n",
    "                if exp_type == 'SIP':\n",
    "                    F_fastq = '_'.join(['library', str(lib), 'window_1.72-1.77_reads_f.fastq.gz'])\n",
    "                    R_fastq = '_'.join(['library', str(lib), 'window_1.72-1.77_reads_r.fastq.gz'])\n",
    "                elif exp_type == 'nonSIP':\n",
    "                    F_fastq = '_'.join(['nonSIP_library', str(lib), 'reads_f.fastq.gz'])\n",
    "                    R_fastq = '_'.join(['nonSIP_library', str(lib), 'reads_r.fastq.gz'])\n",
    "                else:\n",
    "                    print(\"Error with selecting files\")\n",
    "                F_fastq = os.path.join(fastqDir, F_fastq)\n",
    "                R_fastq = os.path.join(fastqDir, R_fastq)\n",
    "                    \n",
    "                if not os.path.isfile(F_fastq):\n",
    "                    print(' '.join([F_fastq, 'does not exist']))\n",
    "                if not os.path.isfile(R_fastq):\n",
    "                    print(' '.join([R_fastq, 'does not exist']))\n",
    "                \n",
    "                # Reorder reads so that they are paired\n",
    "                print('Reordering reads')\n",
    "                cmd = ''.join(['repair.sh in1=', F_fastq, ' in2=', R_fastq, \n",
    "                               ' out1=repaired1.fastq.gz out2=repaired2.fastq.gz outs=repairedS.fastq.gz -Xmx20g'])\n",
    "                os.system(cmd)\n",
    "                #print(cmd)\n",
    "                \n",
    "                # Map reads\n",
    "                mapStats = '_'.join(['lib', str(lib), 'mapping_stats.txt'])\n",
    "                mapHist = '_'.join(['lib', str(lib), 'mapping_hist.txt'])\n",
    "                binCov = '_'.join(['lib', str(lib), 'binned_coverage.txt'])\n",
    "\n",
    "                print('Mapping reads')         \n",
    "                cmd = ''.join(['bbmap.sh ',\n",
    "                               'in1=repaired1.fastq.gz ',\n",
    "                               'in2=repaired2.fastq.gz ',\n",
    "                               'ref=', cat_fasta, \n",
    "                               ' t=15 nodisk ',\n",
    "                               'covstats=', mapStats,\n",
    "                               ' covhist=', mapHist,\n",
    "                               ' bincov=', binCov, \n",
    "                               ' -Xmx20g'])\n",
    "                os.system(cmd)\n",
    "                #print(cmd)\n",
    "                \n",
    "                # Remove \"repaired\" reads\n",
    "                print('Removing reordered reads')\n",
    "                cmd = 'rm repaired1.fastq.gz repaired2.fastq.gz repairedS.fastq.gz'\n",
    "                os.system(cmd)\n",
    "                #print(cmd)\n",
    "                \n",
    "                print('\\n')\n",
    "\n",
    "            print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
